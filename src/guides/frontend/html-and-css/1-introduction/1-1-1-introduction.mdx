---
title: "Introduction"
slug: "introduction"
category: "frontend"
subcategory: "html-and-css"
curriculum: "introduction"
---

import { LessonCallout } from "@/components/LessonCallout";
import { StaticTweet } from "@/components/StaticTweet";

I spent the past few months diving into the realm of Raymarching and studying some of its applications that may come in handy for future 3D projects, and while I managed to build a pretty diverse set of scenes, all of them consisted of rendering _surfaces or solid objects_. [My blog post on Raymarching](/posts/painting-with-math-a-gentle-study-of-raymarching/) covered some of the many impressive capabilities of this rendering technique, and as I mentioned at the end of that post, that was only the tip of the iceberg; there is _a lot more_ we can do with it.

I spent quite some time digging through talks, videos, and articles on how game engines solve the problem of physically accurate clouds and all the techniques involved in them. It's been a journey, and I wanted to dedicate this last section to this topic because I find the subject fascinating: from a couple of physical principles of actual real-life clouds, we can render clouds in WebGL using Volumetric Raymarching!

I spent a great deal of time exploring the different ways I could use Raymarching to render clouds, from fully wrapping my head around **the basics of Volumetric Raymarching** to **leveraging physically based properties of clouds** to try getting a more realistic output while also trying to squeeze as much performance out of my scenes with neat **performance improvement tips** I learned along the way. I cover all of that in this article, which I hope can serve you as a field guide for your own volumetric rendering experiments and learnings.

<LessonCallout variant="info" label="Before you start">

üëâ This article assumes you have basic knowledge about shaders, noise, and GLSL, or read [The Study of Shaders with React Three Fiber](/posts/the-study-of-shaders-with-react-three-fiber/) as well as some notions about Raymarching, which you can learn more about in [Painting with Math: A Gentle Study of Raymarching](/posts/painting-with-math-a-gentle-study-of-raymarching/).

</LessonCallout>

<LessonCallout label="Sources" variant="info">

- [EA Forstbite physically based sky atmosphere and cloud rendering](https://www.ea.com/frostbite/news/physically-based-sky-atmosphere-and-cloud-rendering) by Sebastien Hillaire
- [Physically Based and Scalable Atmospheres in Unreal Engine](https://www.youtube.com/watch?v=SW30QX1wxTY&ab_channel=SIGGRAPHPhysicallyBasedShadingCourse) by Sebastien Hillaire
- [How Big Budget AAA Games Render Clouds](https://www.youtube.com/watch?v=Qj_tK_mdRc) by SimonDev
- [Scalar Spatiotemporal Blue Noise Masks](https://www.ea.com/seed/news/egsr-2022-blue-noise)
- [The Real-tile Volumetric Cloudscapes of Horizon Zero Dawn](https://www.guerrilla-games.com/media/News/Files/The-Real-time-Volumetric-Cloudscapes-of-Horizon-Zero-Dawn.pdf) by Andrew Schneider
- [Volumetric Rendering](https://wallisc.github.io/rendering/2020/05/02/Volumetric-Rendering-Part-2.html) by Chris Wallis
- [Directional Derivative](https://iquilezles.org/articles/derivative/) by Inigo Quilez

Special thanks to everyone who posted Volumetric rendering demos on Shadertoy, they helped me a lot!

</LessonCallout>

## Volumetric rendering: Raymarching with a twist

In my previous blog post on Raymarching, we saw that the technique relied on:

- **Signed Distance Fields**: functions that return the distance of a given point in space to the surface of an object
- **A Raymarching loop** where we **march step-by-step** alongside rays cast **from an origin point** (a camera, the observer's eye) **through each pixel of an output image**, and we calculate the distance to the object's surface using our SDF. Once that distance is small enough, we can draw a pixel.

If you've practiced this technique on some of your own scenes, you're in luck: Volumetric Raymarching relies on _the same principles_: there's a loop, rays cast from an origin, and SDFs. However, since we're rendering volumes instead of surfaces, there's a tiny twist to the technique üëÄ.

### How to sample a volume

The first time we got introduced to the concept of SDF, we learned that it was important _not to step inside_ the object during our Raymarching loop to have a beautiful render. I even emphasized that fact in one of my diagrams showcasing 3 points relative to an object:

- `P1` is located far from the surface, in green, representing a _positive_ distance to the surface.
- `P2` is located at a close distance Œµ to the surface, in orange,
- `P3` positioned **inside** the object, in red, representing a **negative** distance to the surface.

Our `raymarch` function: we'll need to march at a **constant step size** and start drawing only once **the density is over 0**.

Now comes another question: _what shall we draw once our density is positive to represent a volume?_
For this first example, we can keep things simple and play with the `alpha` channel of our colors to make it proportional to the density of our volume: the denser our object gets as we march into it, the more opaque/darker it will be.

We now know and applied the basics of Volumetric Raymarching. So far, we only rendered a simple volumetric sphere with constant density as we march through the volume, which is a good start. We can now try using that simple scene as a foundation to render something more interesting: **clouds!**

### Noisy Volume

Going from our simple SDF of a sphere to a cloud consists of drawing it with _a bit more noise_. Clouds don't have a uniform shape nor do they have a uniform density, thus we need to introduce some organic randomness through noise in our Raymarching loop. If you read [some of](/posts/the-study-of-shaders-with-react-three-fiber/) [my previous articles](/posts/painting-with-math-a-gentle-study-of-raymarching/), you should already be familiar with the concept of:

1. Noise, Perlin noise, and value noise derivative
2. Fractal Brownian Motion, or FBM.
3. Texture based noise.

To generate raymarched landscapes, we used a noise texture, noise derivatives, and FBM to get a detailed organic result. We'll rely on some of those concepts to create organic randomness and obtain a cloud from our SDF ‚òÅÔ∏è.

<LessonCallout variant="danger">

The directional derivative method to calculate diffuse lighting works only with a few light sources. That is an acceptable limitation, as our scenes only feature one light source: the sun.

</LessonCallout>

<StaticTweet id="1859996269948907914" client:load />
